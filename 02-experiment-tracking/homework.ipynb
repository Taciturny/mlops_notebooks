{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "mlflow_version = mlflow.__version__\n",
    "print(\"MLflow version:\", mlflow_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"C:\\Users\\USER\\Desktop\\Supplementary Data\\MLOPs\\02-experiment-tracking\\preprocess_data.py\" --raw_data_path ./data --dest_path ./output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = \" C:\\Users\\USER\\Desktop\\Supplementary Data\\MLOPs\\02-experiment-tracking\\output\\dv.pkl\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Get the size of the file in bytes\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(\"Size of the DictVectorizer file:\", file_size, \"bytes\")\n",
    "else:\n",
    "    print(\"File not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the DictVectorizer file: 150.06 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = r\"C:\\Users\\USER\\Desktop\\Supplementary Data\\MLOPs\\02-experiment-tracking\\output\\dv.pkl\"\n",
    "\n",
    "file_size_kb = os.path.getsize(file_path) / 1024  # Convert bytes to kilobytes\n",
    "\n",
    "print(f\"Size of the DictVectorizer file: {file_size_kb:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/27 15:35:33 INFO mlflow.tracking.fluent: Experiment with name 'Random-forest-experiment' does not exist. Creating a new experiment.\n",
      "2023/05/27 15:36:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\USER\\.conda\\envs\\exp-track\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "!python \"C:\\Users\\USER\\Desktop\\Supplementary Data\\MLOPs\\02-experiment-tracking\\train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ui, the max_depth is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/27 16:08:36 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-hyperopt' does not exist. Creating a new experiment.\n",
      "\u001b[32m[I 2023-05-27 16:08:36,622]\u001b[0m A new study created in memory with name: no-name-b9fb0ba3-e889-4997-b0dc-01f77f8281f3\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:08:56,130]\u001b[0m Trial 0 finished with value: 2.451379690825458 and parameters: {'n_estimators': 25, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 2.451379690825458.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:08:58,082]\u001b[0m Trial 1 finished with value: 2.4667366020368333 and parameters: {'n_estimators': 16, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 0 with value: 2.451379690825458.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:09:14,837]\u001b[0m Trial 2 finished with value: 2.449827329704216 and parameters: {'n_estimators': 34, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:09:20,786]\u001b[0m Trial 3 finished with value: 2.460983516558473 and parameters: {'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:09:28,854]\u001b[0m Trial 4 finished with value: 2.453877262701052 and parameters: {'n_estimators': 22, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:09:33,877]\u001b[0m Trial 5 finished with value: 2.4720122094960733 and parameters: {'n_estimators': 35, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:09:54,169]\u001b[0m Trial 6 finished with value: 2.4516421799356767 and parameters: {'n_estimators': 28, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:09:55,923]\u001b[0m Trial 7 finished with value: 2.5374040268274087 and parameters: {'n_estimators': 34, 'max_depth': 1, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:10:05,965]\u001b[0m Trial 8 finished with value: 2.455971238567075 and parameters: {'n_estimators': 12, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-05-27 16:10:07,857]\u001b[0m Trial 9 finished with value: 2.486106021576535 and parameters: {'n_estimators': 22, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python \"C:\\Users\\USER\\Desktop\\Supplementary Data\\MLOPs\\02-experiment-tracking\\hpo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/27 16:32:31 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-best-models' does not exist. Creating a new experiment.\n",
      "2023/05/27 16:33:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\USER\\.conda\\envs\\exp-track\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2023/05/27 16:34:09 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/277188287618622766/002b86d34b06417c8accfdb97cadd662/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2023/05/27 16:35:35 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/277188287618622766/36bc21ebf9ee44b79996542c045a46cd/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2023/05/27 16:37:24 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/277188287618622766/3e937e9c626b4f379a403d3ef97ceda4/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2023/05/27 16:38:40 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/277188287618622766/2dea92decde14429beb2bf02bcb4f48f/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2023/05/27 16:39:57 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/277188287618622766/4a683bf7dfa546d2b11b0ec82b5799a6/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Successfully registered model 'random-forest'.\n",
      "2023/05/27 16:39:58 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest, version 1\n",
      "Created version '1' of model 'random-forest'.\n"
     ]
    }
   ],
   "source": [
    "!python \"C:\\Users\\USER\\Desktop\\Supplementary Data\\MLOPs\\02-experiment-tracking\\register_model.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the test RMSE of the best model?\n",
    "\n",
    "2.291"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now explore your best model in the model registry using UI. What information does the model registry contain about each model?\n",
    "\n",
    "Version number = 1\n",
    "\n",
    "Source experiment = legendary-quail-370\n",
    "\n",
    "Model signature = Input: Tensor (dtype: float64, shape: [-1,6683]) and Output: Tensor (dtype: float64, shape: [-1])\n",
    "\n",
    "All the above answers are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-track",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
