{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d6f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9380d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan = pd.read_parquet('./data/yellow_tripdata_2022-01.parquet')\n",
    "df_feb = pd.read_parquet('./data/yellow_tripdata_2022-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c7444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_dataframe(filename):\n",
    "#     if filename.endswith('.csv'):\n",
    "#         df = pd.read_csv(filename)\n",
    "        \n",
    "#     elif filename.endswith('.parquet'):\n",
    "#         df = pd.read_parquet(filename)\n",
    "\n",
    "#     df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "#     df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "#     df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "#     categorical = ['PULocationID', 'DOLocationID']\n",
    "#     df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fb67f",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "* Read the data for January. How many columns are there?\n",
    "\n",
    "\n",
    "Answer:\n",
    "\n",
    "D) 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1974786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 19\n"
     ]
    }
   ],
   "source": [
    "# Get the number of columns\n",
    "num_columns = len(df_jan.columns)\n",
    "\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe67b6",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "* What's the standard deviation of the trips duration in January?\n",
    "\n",
    "Answer:\n",
    "\n",
    "B) 46.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8e723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan['duration'] = df_jan.tpep_dropoff_datetime - df_jan.tpep_pickup_datetime\n",
    "df_jan.duration = df_jan.duration.apply(lambda td: td.total_seconds() / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43828952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.44530513776499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan.duration.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4718c4",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "Answer:\n",
    "D) 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cfedb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of Records Left: 98.27547930522405\n"
     ]
    }
   ],
   "source": [
    "new_df = df_jan[(df_jan.duration >= 1) & (df_jan.duration <= 60)]\n",
    "frac_df = len(new_df) / len(df_jan)\n",
    "\n",
    "print(\"Fraction of Records Left:\", frac_df * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999b948",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer\n",
    "* Get a feature matrix from it\n",
    "\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "Answer:\n",
    "\n",
    "A) 515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d9d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the feature matrix: 515\n"
     ]
    }
   ],
   "source": [
    "cats = ['PULocationID', 'DOLocationID']\n",
    "target = ['duration']\n",
    "\n",
    "# convert to str to perform vec\n",
    "new_df[cats] = new_df[cats].astype(str)\n",
    "\n",
    "# Turn the dataframe into a list of dictionaries\n",
    "train_id = new_df[cats].to_dict('records')\n",
    "\n",
    "# Fit and obtain the feature matrix using the dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_id)\n",
    "\n",
    "# Get the dimensionality of the feature matrix\n",
    "num_columns = X_train.shape[1]\n",
    "print(\"Dimensionality of the feature matrix:\", num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9492b1a1",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "* Train a plain linear regression model with default parameters\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "Answer: \n",
    "\n",
    "A) 6.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09126c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 6.986191072971965\n"
     ]
    }
   ],
   "source": [
    "y_train = new_df['duration'].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "rmse = mean_squared_error(y_train, y_pred, squared=False)\n",
    "print(\"RMSE on train:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65590b",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2022).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "Answer:\n",
    "\n",
    "A) 7.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d319f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_fit(df):\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    new_df = df[(df['duration'] >= 1) & (df['duration'] <= 60)]\n",
    "\n",
    "    categorical_cols = ['PULocationID', 'DOLocationID']\n",
    "    new_df[categorical_cols] = new_df[categorical_cols].astype(str)\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(new_df[categorical_cols].to_dict('records'))\n",
    "    y_train = new_df['duration'].values\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    return lr, dv\n",
    "\n",
    "def transform_and_evaluate(df, model, dv):\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    new_df = df[(df['duration'] >= 1) & (df['duration'] <= 60)]\n",
    "\n",
    "    categorical_cols = ['PULocationID', 'DOLocationID']\n",
    "    new_df[categorical_cols] = new_df[categorical_cols].astype(str)\n",
    "\n",
    "    X_eval = dv.transform(new_df[categorical_cols].to_dict('records'))\n",
    "    y_eval = new_df['duration'].values\n",
    "\n",
    "    y_preds = model.predict(X_eval)\n",
    "    rmse = mean_squared_error(y_eval, y_preds, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def train_and_evaluate(df_train, df_eval):\n",
    "    model, dv = process_and_fit(df_train)\n",
    "    rmse = transform_and_evaluate(df_eval, model, dv)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3341cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, dv = process_and_fit(df_jan)\n",
    "rmse = transform_and_evaluate(df_feb, model, dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a19452a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation train: 7.786409044614996\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on validation train:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047f869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
